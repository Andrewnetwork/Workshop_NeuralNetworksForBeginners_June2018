{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "** About the Data **\n",
    "\n",
    "We are using the MNIST data obtained from the [digit recognizer competition on Kaggle](https://www.kaggle.com/c/digit-recognizer/data). MNIST was produced by [Yann Lecun et al.](http://yann.lecun.com/exdb/mnist/) and their page has a great list of benchmark results. The street view house numbers (SVHN) was obtained from [stanfords website](http://ufldl.stanford.edu/housenumbers/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from keras.layers import Input, Dense, Dropout,Conv2D,MaxPooling2D,Flatten,GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform, Load (ETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistTrainingData = pd.read_csv(\"MNIST_train_28x28.csv\")\n",
    "mnistTrainingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistTrain_y = mnistTrainingData.values[:,0]\n",
    "mnistTrain_x = mnistTrainingData.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ef663e78f44a6ebe1e32cdd15d49a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='imSel'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dispMNIST>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dispMNIST(imSel = 0):\n",
    "    plt.title(\"Digit class: {0}\".format(mnistTrain_y[imSel]))\n",
    "    plt.imshow(mnistTrain_x[imSel].reshape(28,28))\n",
    "    plt.show()\n",
    "\n",
    "interact(dispMNIST,imSel=(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "imSel = 0\n",
    "svhn = sio.loadmat(\"SVHN_train_32x32.mat\")\n",
    "svhn_x = svhn[\"X\"]\n",
    "svhn_x = np.moveaxis(svhn_x,-1,0)\n",
    "svhn_y = svhn[\"y\"]\n",
    "svhn_y = (svhn_y-1).reshape(svhn_y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc6d096b6a545869bf15851c70092cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='imSel'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.dispSVHN>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dispSVHN(imSel = 0):\n",
    "    plt.title(\"Digit class: {0}\".format(svhn_y[imSel][0]))\n",
    "    plt.imshow(svhn_x[imSel,:,:,:])\n",
    "    plt.show()\n",
    "    \n",
    "interact(dispSVHN,imSel=(0,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_6 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 13,878\n",
      "Trainable params: 13,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 12.3850 - acc: 0.2236\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 11.1250 - acc: 0.3020\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 11.1071 - acc: 0.3071\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 11.1068 - acc: 0.3074\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 11.1046 - acc: 0.3080\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 11.1006 - acc: 0.3091\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 11.0986 - acc: 0.3095\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 11.0957 - acc: 0.3104\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 10.7827 - acc: 0.3163\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 0.3641 - acc: 0.8844\n"
     ]
    }
   ],
   "source": [
    "def makeModel(inputSize):\n",
    "    inputs = Input(shape=inputSize,name=\"input\")\n",
    "    x = Conv2D(32, (3, 3), input_shape=(28, 28,1), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(x)\n",
    "    x = Conv2D(32, (3, 3), input_shape=(28, 28,1), padding='same', activation='relu')(x)\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    out = Dense(10,activation='softmax', name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = makeModel((28,28,1,))\n",
    "model.summary()\n",
    "hist = model.fit(mnistTrain_x.reshape(mnistTrain_x.shape[0],28,28,1), to_categorical(mnistTrain_y,10),batch_size=100,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73257/73257 [==============================] - 6s 87us/step - loss: 2.7186 - acc: 0.1796\n",
      "Epoch 2/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 2.0106 - acc: 0.2958\n",
      "Epoch 3/100\n",
      "73257/73257 [==============================] - 6s 83us/step - loss: 1.6915 - acc: 0.4219\n",
      "Epoch 4/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 1.5131 - acc: 0.4925\n",
      "Epoch 5/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.3964 - acc: 0.5388\n",
      "Epoch 6/100\n",
      "73257/73257 [==============================] - 6s 83us/step - loss: 1.2998 - acc: 0.5777\n",
      "Epoch 7/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.2321 - acc: 0.6054\n",
      "Epoch 8/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.1770 - acc: 0.6246\n",
      "Epoch 9/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.1458 - acc: 0.6352\n",
      "Epoch 10/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.1158 - acc: 0.6464\n",
      "Epoch 11/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.0898 - acc: 0.6545\n",
      "Epoch 12/100\n",
      "73257/73257 [==============================] - 6s 83us/step - loss: 1.0728 - acc: 0.6574\n",
      "Epoch 13/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.0504 - acc: 0.6670\n",
      "Epoch 14/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.0342 - acc: 0.6701\n",
      "Epoch 15/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 1.0244 - acc: 0.6723\n",
      "Epoch 16/100\n",
      "73257/73257 [==============================] - 6s 83us/step - loss: 1.0018 - acc: 0.6802\n",
      "Epoch 17/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 0.9873 - acc: 0.6850\n",
      "Epoch 18/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9763 - acc: 0.6874\n",
      "Epoch 19/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 0.9700 - acc: 0.6897\n",
      "Epoch 20/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9597 - acc: 0.6920\n",
      "Epoch 21/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9569 - acc: 0.6921\n",
      "Epoch 22/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9467 - acc: 0.6959\n",
      "Epoch 23/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9399 - acc: 0.6964\n",
      "Epoch 24/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9363 - acc: 0.6985\n",
      "Epoch 25/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 0.9246 - acc: 0.7034\n",
      "Epoch 26/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 0.9222 - acc: 0.7032\n",
      "Epoch 27/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 0.9108 - acc: 0.7068\n",
      "Epoch 28/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.9047 - acc: 0.7074\n",
      "Epoch 29/100\n",
      "73257/73257 [==============================] - 6s 84us/step - loss: 0.9066 - acc: 0.7066\n",
      "Epoch 30/100\n",
      "73257/73257 [==============================] - 6s 83us/step - loss: 0.8958 - acc: 0.7114\n",
      "Epoch 31/100\n",
      "73257/73257 [==============================] - 6s 82us/step - loss: 0.8957 - acc: 0.7103\n",
      "Epoch 32/100\n",
      "73257/73257 [==============================] - 6s 84us/step - loss: 0.8927 - acc: 0.7122\n",
      "Epoch 33/100\n",
      "73257/73257 [==============================] - 6s 85us/step - loss: 0.8867 - acc: 0.7119\n",
      "Epoch 34/100\n",
      "73257/73257 [==============================] - 6s 84us/step - loss: 0.8879 - acc: 0.7121\n",
      "Epoch 35/100\n",
      "73257/73257 [==============================] - 6s 83us/step - loss: 0.8795 - acc: 0.7153\n",
      "Epoch 36/100\n",
      "73257/73257 [==============================] - 6s 84us/step - loss: 0.8792 - acc: 0.7155\n",
      "Epoch 37/100\n",
      "73257/73257 [==============================] - 6s 84us/step - loss: 0.8755 - acc: 0.7165\n",
      "Epoch 38/100\n",
      "73257/73257 [==============================] - 6s 84us/step - loss: 0.8730 - acc: 0.7170\n",
      "Epoch 39/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8656 - acc: 0.7201\n",
      "Epoch 40/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8691 - acc: 0.7180\n",
      "Epoch 41/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8650 - acc: 0.7204\n",
      "Epoch 42/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8604 - acc: 0.7210\n",
      "Epoch 43/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8561 - acc: 0.7210\n",
      "Epoch 44/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8568 - acc: 0.7221\n",
      "Epoch 45/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8486 - acc: 0.7240\n",
      "Epoch 46/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8498 - acc: 0.7231\n",
      "Epoch 47/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8485 - acc: 0.7259\n",
      "Epoch 48/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8493 - acc: 0.7238\n",
      "Epoch 49/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8462 - acc: 0.7250\n",
      "Epoch 50/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8405 - acc: 0.7279\n",
      "Epoch 51/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8368 - acc: 0.7275\n",
      "Epoch 52/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8321 - acc: 0.7287\n",
      "Epoch 53/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8343 - acc: 0.7285\n",
      "Epoch 54/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8353 - acc: 0.7279\n",
      "Epoch 55/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8332 - acc: 0.7287\n",
      "Epoch 56/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8353 - acc: 0.7293\n",
      "Epoch 57/100\n",
      "73257/73257 [==============================] - 6s 81us/step - loss: 0.8304 - acc: 0.7298\n",
      "Epoch 58/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8258 - acc: 0.7305\n",
      "Epoch 59/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8255 - acc: 0.7311\n",
      "Epoch 60/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8272 - acc: 0.7303\n",
      "Epoch 61/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8286 - acc: 0.7307\n",
      "Epoch 62/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8197 - acc: 0.7331\n",
      "Epoch 63/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8208 - acc: 0.7331\n",
      "Epoch 64/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8228 - acc: 0.7327\n",
      "Epoch 65/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8170 - acc: 0.7337\n",
      "Epoch 66/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8188 - acc: 0.7324\n",
      "Epoch 67/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8168 - acc: 0.7335\n",
      "Epoch 68/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8123 - acc: 0.7348\n",
      "Epoch 69/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8096 - acc: 0.7366\n",
      "Epoch 70/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8139 - acc: 0.7347\n",
      "Epoch 71/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8119 - acc: 0.7343\n",
      "Epoch 72/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8114 - acc: 0.7358\n",
      "Epoch 73/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8050 - acc: 0.7378\n",
      "Epoch 74/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8109 - acc: 0.7357\n",
      "Epoch 75/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8028 - acc: 0.7394\n",
      "Epoch 76/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8038 - acc: 0.7381\n",
      "Epoch 77/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.8021 - acc: 0.7391\n",
      "Epoch 78/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7993 - acc: 0.7388\n",
      "Epoch 79/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7975 - acc: 0.7392\n",
      "Epoch 80/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.7990 - acc: 0.7399\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.7978 - acc: 0.7387\n",
      "Epoch 82/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7957 - acc: 0.7410\n",
      "Epoch 83/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.8007 - acc: 0.7393\n",
      "Epoch 84/100\n",
      "73257/73257 [==============================] - 6s 78us/step - loss: 0.7954 - acc: 0.7403\n",
      "Epoch 85/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7890 - acc: 0.7424\n",
      "Epoch 86/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7891 - acc: 0.7425\n",
      "Epoch 87/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.7853 - acc: 0.7442\n",
      "Epoch 88/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7861 - acc: 0.7444\n",
      "Epoch 89/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7852 - acc: 0.7443\n",
      "Epoch 90/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.7822 - acc: 0.7464\n",
      "Epoch 91/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7800 - acc: 0.7455\n",
      "Epoch 92/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.7791 - acc: 0.7448\n",
      "Epoch 93/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7773 - acc: 0.7460\n",
      "Epoch 94/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7799 - acc: 0.7443\n",
      "Epoch 95/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7744 - acc: 0.7480\n",
      "Epoch 96/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7731 - acc: 0.7479\n",
      "Epoch 97/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7737 - acc: 0.7491\n",
      "Epoch 98/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7712 - acc: 0.7482\n",
      "Epoch 99/100\n",
      "73257/73257 [==============================] - 6s 79us/step - loss: 0.7717 - acc: 0.7496\n",
      "Epoch 100/100\n",
      "73257/73257 [==============================] - 6s 80us/step - loss: 0.7761 - acc: 0.7469\n"
     ]
    }
   ],
   "source": [
    "model = makeModel((32,32,3,))\n",
    "hist = model.fit(svhn_x, to_categorical(svhn_y,10),batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.predict(mnistTrain_x[0].reshape(1,28,28,1))\n",
    "np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(mnistTrain_y,10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257,)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73257,)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
