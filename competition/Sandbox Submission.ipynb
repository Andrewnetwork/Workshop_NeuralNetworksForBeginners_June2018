{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andre\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from keras.layers import Input, Dense, Dropout,Conv2D,MaxPooling2D,Flatten\n",
    "from keras.layers import GlobalMaxPooling2D,UpSampling2D,GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.color import rgb2grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"train_x.npy\")\n",
    "train_y = np.load(\"train_y.npy\")\n",
    "train_y = train_y - 1\n",
    "test_x  = np.load(\"test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel(inputSize):\n",
    "    inputs = Input(shape=inputSize,name=\"input\")\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid')(x)\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dense(100,activation='relu')(x)\n",
    "    out = Dense(10,activation='softmax', name=\"output\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['acc'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def learningCurves(hist):\n",
    "    histLoss_train      = hist.history['loss']\n",
    "    epochs = len(histLoss_train)\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    \n",
    "    plt.plot(range(epochs),histLoss_train, label=\"Training Loss\", color=\"#acc6ef\")\n",
    "\n",
    "\n",
    "    plt.xlabel('Epochs',fontsize=14)\n",
    "    plt.title(\"Learning Curves\",fontsize=20)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_5 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 14,454\n",
      "Trainable params: 14,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "43954/43954 [==============================] - 4s 80us/step - loss: 3.3593 - acc: 0.1718\n",
      "Epoch 2/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 2.0992 - acc: 0.2578\n",
      "Epoch 3/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.9461 - acc: 0.3153\n",
      "Epoch 4/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.8328 - acc: 0.3601\n",
      "Epoch 5/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.7312 - acc: 0.4048\n",
      "Epoch 6/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.6429 - acc: 0.4440\n",
      "Epoch 7/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 1.5678 - acc: 0.4750\n",
      "Epoch 8/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.4913 - acc: 0.5077\n",
      "Epoch 9/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.4349 - acc: 0.5286\n",
      "Epoch 10/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.3824 - acc: 0.5492\n",
      "Epoch 11/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.3396 - acc: 0.5641\n",
      "Epoch 12/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 1.2991 - acc: 0.5787\n",
      "Epoch 13/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.2870 - acc: 0.5831\n",
      "Epoch 14/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.2646 - acc: 0.5901\n",
      "Epoch 15/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 1.2425 - acc: 0.5981\n",
      "Epoch 16/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.2316 - acc: 0.5991\n",
      "Epoch 17/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.2188 - acc: 0.6044\n",
      "Epoch 18/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.2200 - acc: 0.6017\n",
      "Epoch 19/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.2039 - acc: 0.6070\n",
      "Epoch 20/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.1891 - acc: 0.6141\n",
      "Epoch 21/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.1766 - acc: 0.6163\n",
      "Epoch 22/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.1637 - acc: 0.6215\n",
      "Epoch 23/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.1429 - acc: 0.6271\n",
      "Epoch 24/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 1.1244 - acc: 0.6364\n",
      "Epoch 25/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.1142 - acc: 0.6390\n",
      "Epoch 26/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.0985 - acc: 0.6454\n",
      "Epoch 27/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 1.0855 - acc: 0.6489\n",
      "Epoch 28/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.0802 - acc: 0.6495\n",
      "Epoch 29/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.0734 - acc: 0.6503\n",
      "Epoch 30/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.0570 - acc: 0.6555\n",
      "Epoch 31/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 1.0555 - acc: 0.6584\n",
      "Epoch 32/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.0553 - acc: 0.6571\n",
      "Epoch 33/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.0394 - acc: 0.6633\n",
      "Epoch 34/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 1.0236 - acc: 0.6680\n",
      "Epoch 35/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 1.0251 - acc: 0.6650\n",
      "Epoch 36/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 1.0074 - acc: 0.6719\n",
      "Epoch 37/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 1.0064 - acc: 0.6728\n",
      "Epoch 38/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9918 - acc: 0.6746\n",
      "Epoch 39/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9936 - acc: 0.6771\n",
      "Epoch 40/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.9868 - acc: 0.6788\n",
      "Epoch 41/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9785 - acc: 0.6806\n",
      "Epoch 42/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.9771 - acc: 0.6814\n",
      "Epoch 43/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9754 - acc: 0.6810\n",
      "Epoch 44/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9664 - acc: 0.6837\n",
      "Epoch 45/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9632 - acc: 0.6860\n",
      "Epoch 46/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9597 - acc: 0.6859\n",
      "Epoch 47/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9513 - acc: 0.6895\n",
      "Epoch 48/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9379 - acc: 0.6931\n",
      "Epoch 49/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9322 - acc: 0.6972\n",
      "Epoch 50/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.9302 - acc: 0.6950\n",
      "Epoch 51/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9206 - acc: 0.6991\n",
      "Epoch 52/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.9160 - acc: 0.7014\n",
      "Epoch 53/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.9177 - acc: 0.7011\n",
      "Epoch 54/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.9098 - acc: 0.7033\n",
      "Epoch 55/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9123 - acc: 0.7028\n",
      "Epoch 56/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9060 - acc: 0.7036\n",
      "Epoch 57/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.9022 - acc: 0.7061\n",
      "Epoch 58/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8933 - acc: 0.7087\n",
      "Epoch 59/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8937 - acc: 0.7073\n",
      "Epoch 60/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8889 - acc: 0.7083\n",
      "Epoch 61/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8877 - acc: 0.7085\n",
      "Epoch 62/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8885 - acc: 0.7093\n",
      "Epoch 63/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.8783 - acc: 0.7119\n",
      "Epoch 64/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.8742 - acc: 0.7140\n",
      "Epoch 65/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8672 - acc: 0.7164\n",
      "Epoch 66/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8718 - acc: 0.7151\n",
      "Epoch 67/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8655 - acc: 0.7172\n",
      "Epoch 68/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8647 - acc: 0.7188\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8612 - acc: 0.7209\n",
      "Epoch 70/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8583 - acc: 0.7181\n",
      "Epoch 71/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8593 - acc: 0.7168\n",
      "Epoch 72/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8568 - acc: 0.7196\n",
      "Epoch 73/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8575 - acc: 0.7211\n",
      "Epoch 74/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8563 - acc: 0.7208\n",
      "Epoch 75/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.8472 - acc: 0.7221\n",
      "Epoch 76/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8407 - acc: 0.7223\n",
      "Epoch 77/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8446 - acc: 0.7236\n",
      "Epoch 78/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8422 - acc: 0.7240\n",
      "Epoch 79/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.8441 - acc: 0.7212\n",
      "Epoch 80/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8478 - acc: 0.7226\n",
      "Epoch 81/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8362 - acc: 0.7283\n",
      "Epoch 82/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8397 - acc: 0.7249\n",
      "Epoch 83/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8348 - acc: 0.7261\n",
      "Epoch 84/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8363 - acc: 0.7277\n",
      "Epoch 85/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8309 - acc: 0.7284\n",
      "Epoch 86/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8365 - acc: 0.7255\n",
      "Epoch 87/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8271 - acc: 0.7294\n",
      "Epoch 88/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8291 - acc: 0.7300\n",
      "Epoch 89/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8239 - acc: 0.7298\n",
      "Epoch 90/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8287 - acc: 0.7292\n",
      "Epoch 91/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8174 - acc: 0.7313\n",
      "Epoch 92/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.8243 - acc: 0.7298\n",
      "Epoch 93/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8207 - acc: 0.7310\n",
      "Epoch 94/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 0.8233 - acc: 0.7287\n",
      "Epoch 95/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8207 - acc: 0.7316\n",
      "Epoch 96/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.8175 - acc: 0.7300\n",
      "Epoch 97/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8157 - acc: 0.7320\n",
      "Epoch 98/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8120 - acc: 0.7332\n",
      "Epoch 99/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8129 - acc: 0.7325\n",
      "Epoch 100/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8130 - acc: 0.7332\n",
      "Epoch 101/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8103 - acc: 0.7344\n",
      "Epoch 102/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8077 - acc: 0.7339\n",
      "Epoch 103/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8037 - acc: 0.7361\n",
      "Epoch 104/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.8057 - acc: 0.7357\n",
      "Epoch 105/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8107 - acc: 0.7347\n",
      "Epoch 106/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8058 - acc: 0.7348\n",
      "Epoch 107/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7990 - acc: 0.7362\n",
      "Epoch 108/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8035 - acc: 0.7336\n",
      "Epoch 109/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7955 - acc: 0.7400\n",
      "Epoch 110/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8021 - acc: 0.7350\n",
      "Epoch 111/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.8024 - acc: 0.7374\n",
      "Epoch 112/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7990 - acc: 0.7392\n",
      "Epoch 113/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7948 - acc: 0.7388\n",
      "Epoch 114/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8000 - acc: 0.7372\n",
      "Epoch 115/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7961 - acc: 0.7361\n",
      "Epoch 116/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.8000 - acc: 0.7370\n",
      "Epoch 117/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7888 - acc: 0.7401\n",
      "Epoch 118/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7900 - acc: 0.7407\n",
      "Epoch 119/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7987 - acc: 0.7390\n",
      "Epoch 120/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7893 - acc: 0.7404\n",
      "Epoch 121/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7955 - acc: 0.7382\n",
      "Epoch 122/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7894 - acc: 0.7407\n",
      "Epoch 123/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7886 - acc: 0.7406\n",
      "Epoch 124/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7890 - acc: 0.7397\n",
      "Epoch 125/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7931 - acc: 0.7370\n",
      "Epoch 126/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7955 - acc: 0.7387\n",
      "Epoch 127/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7824 - acc: 0.7428\n",
      "Epoch 128/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7859 - acc: 0.7407\n",
      "Epoch 129/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7874 - acc: 0.7411\n",
      "Epoch 130/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7847 - acc: 0.7409\n",
      "Epoch 131/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7828 - acc: 0.7399\n",
      "Epoch 132/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7824 - acc: 0.7419\n",
      "Epoch 133/500\n",
      "43954/43954 [==============================] - 3s 79us/step - loss: 0.7771 - acc: 0.7427\n",
      "Epoch 134/500\n",
      "43954/43954 [==============================] - 3s 77us/step - loss: 0.7858 - acc: 0.7425\n",
      "Epoch 135/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7764 - acc: 0.7449\n",
      "Epoch 136/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7827 - acc: 0.7419\n",
      "Epoch 137/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7829 - acc: 0.7423\n",
      "Epoch 138/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7741 - acc: 0.7438\n",
      "Epoch 139/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7817 - acc: 0.7429\n",
      "Epoch 140/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7797 - acc: 0.7428\n",
      "Epoch 141/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7742 - acc: 0.7443\n",
      "Epoch 142/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7765 - acc: 0.7449\n",
      "Epoch 143/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 0.7740 - acc: 0.7476\n",
      "Epoch 144/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7715 - acc: 0.7438\n",
      "Epoch 145/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7713 - acc: 0.7454\n",
      "Epoch 146/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7691 - acc: 0.7462\n",
      "Epoch 147/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7751 - acc: 0.7440\n",
      "Epoch 148/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7668 - acc: 0.7464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7676 - acc: 0.7462\n",
      "Epoch 150/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7745 - acc: 0.7433\n",
      "Epoch 151/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7725 - acc: 0.7462\n",
      "Epoch 152/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7742 - acc: 0.7429\n",
      "Epoch 153/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7697 - acc: 0.7464\n",
      "Epoch 154/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7748 - acc: 0.7451\n",
      "Epoch 155/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7693 - acc: 0.7440\n",
      "Epoch 156/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7650 - acc: 0.7463\n",
      "Epoch 157/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7643 - acc: 0.7480\n",
      "Epoch 158/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7732 - acc: 0.7447\n",
      "Epoch 159/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7700 - acc: 0.7453\n",
      "Epoch 160/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7619 - acc: 0.7483\n",
      "Epoch 161/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7653 - acc: 0.7474\n",
      "Epoch 162/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7686 - acc: 0.7453\n",
      "Epoch 163/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7636 - acc: 0.7470\n",
      "Epoch 164/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7666 - acc: 0.7474\n",
      "Epoch 165/500\n",
      "43954/43954 [==============================] - 3s 70us/step - loss: 0.7555 - acc: 0.7491\n",
      "Epoch 166/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7621 - acc: 0.7483\n",
      "Epoch 167/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7698 - acc: 0.7452\n",
      "Epoch 168/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7578 - acc: 0.7495\n",
      "Epoch 169/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7627 - acc: 0.7469\n",
      "Epoch 170/500\n",
      "43954/43954 [==============================] - 4s 83us/step - loss: 0.7629 - acc: 0.7481\n",
      "Epoch 171/500\n",
      "43954/43954 [==============================] - 3s 77us/step - loss: 0.7653 - acc: 0.7474\n",
      "Epoch 172/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7600 - acc: 0.7496\n",
      "Epoch 173/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7527 - acc: 0.7519\n",
      "Epoch 174/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7580 - acc: 0.7504\n",
      "Epoch 175/500\n",
      "43954/43954 [==============================] - 3s 78us/step - loss: 0.7633 - acc: 0.7478\n",
      "Epoch 176/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7531 - acc: 0.7514\n",
      "Epoch 177/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7466 - acc: 0.7521\n",
      "Epoch 178/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7520 - acc: 0.7519\n",
      "Epoch 179/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7569 - acc: 0.7508\n",
      "Epoch 180/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7550 - acc: 0.7510\n",
      "Epoch 181/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7487 - acc: 0.7511\n",
      "Epoch 182/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7509 - acc: 0.7514\n",
      "Epoch 183/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7549 - acc: 0.7486\n",
      "Epoch 184/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7539 - acc: 0.7502\n",
      "Epoch 185/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7486 - acc: 0.7510\n",
      "Epoch 186/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7479 - acc: 0.7518\n",
      "Epoch 187/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7500 - acc: 0.7516\n",
      "Epoch 188/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7620 - acc: 0.7485\n",
      "Epoch 189/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7457 - acc: 0.7519\n",
      "Epoch 190/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7457 - acc: 0.7535\n",
      "Epoch 191/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7414 - acc: 0.7545\n",
      "Epoch 192/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7534 - acc: 0.7513\n",
      "Epoch 193/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7498 - acc: 0.7502\n",
      "Epoch 194/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7504 - acc: 0.7497\n",
      "Epoch 195/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7466 - acc: 0.7513\n",
      "Epoch 196/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7463 - acc: 0.7529\n",
      "Epoch 197/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7466 - acc: 0.7541\n",
      "Epoch 198/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7480 - acc: 0.7536\n",
      "Epoch 199/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7439 - acc: 0.7524\n",
      "Epoch 200/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7454 - acc: 0.7540\n",
      "Epoch 201/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7415 - acc: 0.7526\n",
      "Epoch 202/500\n",
      "43954/43954 [==============================] - 3s 79us/step - loss: 0.7444 - acc: 0.7524\n",
      "Epoch 203/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7427 - acc: 0.7550\n",
      "Epoch 204/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7460 - acc: 0.7541\n",
      "Epoch 205/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7420 - acc: 0.7543\n",
      "Epoch 206/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7444 - acc: 0.7531\n",
      "Epoch 207/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7396 - acc: 0.7549\n",
      "Epoch 208/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7410 - acc: 0.7524\n",
      "Epoch 209/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7444 - acc: 0.7544\n",
      "Epoch 210/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7433 - acc: 0.7530\n",
      "Epoch 211/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7337 - acc: 0.7575\n",
      "Epoch 212/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7419 - acc: 0.7544\n",
      "Epoch 213/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7404 - acc: 0.7544\n",
      "Epoch 214/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7448 - acc: 0.7531\n",
      "Epoch 215/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7414 - acc: 0.7541\n",
      "Epoch 216/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7424 - acc: 0.7541\n",
      "Epoch 217/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7415 - acc: 0.7538\n",
      "Epoch 218/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7369 - acc: 0.7559\n",
      "Epoch 219/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7344 - acc: 0.7548\n",
      "Epoch 220/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7406 - acc: 0.7559\n",
      "Epoch 221/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7342 - acc: 0.7585\n",
      "Epoch 222/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7316 - acc: 0.7574\n",
      "Epoch 223/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7398 - acc: 0.7542\n",
      "Epoch 224/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7396 - acc: 0.7551\n",
      "Epoch 225/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7385 - acc: 0.7541\n",
      "Epoch 226/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7298 - acc: 0.7590\n",
      "Epoch 227/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7285 - acc: 0.7581\n",
      "Epoch 228/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7346 - acc: 0.7554\n",
      "Epoch 229/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7313 - acc: 0.7565\n",
      "Epoch 230/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7357 - acc: 0.7548\n",
      "Epoch 231/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7339 - acc: 0.7563\n",
      "Epoch 232/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7385 - acc: 0.7557\n",
      "Epoch 233/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7282 - acc: 0.7576\n",
      "Epoch 234/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7309 - acc: 0.7575\n",
      "Epoch 235/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7325 - acc: 0.7571\n",
      "Epoch 236/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7342 - acc: 0.7562\n",
      "Epoch 237/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7273 - acc: 0.7583\n",
      "Epoch 238/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7341 - acc: 0.7543\n",
      "Epoch 239/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7275 - acc: 0.7589\n",
      "Epoch 240/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7260 - acc: 0.7579\n",
      "Epoch 241/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7346 - acc: 0.7568\n",
      "Epoch 242/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7272 - acc: 0.7606\n",
      "Epoch 243/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7253 - acc: 0.7603\n",
      "Epoch 244/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7296 - acc: 0.7578\n",
      "Epoch 245/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7290 - acc: 0.7577\n",
      "Epoch 246/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7283 - acc: 0.7581\n",
      "Epoch 247/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7228 - acc: 0.7591\n",
      "Epoch 248/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7259 - acc: 0.7596\n",
      "Epoch 249/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7310 - acc: 0.7563\n",
      "Epoch 250/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7208 - acc: 0.7606\n",
      "Epoch 251/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7131 - acc: 0.7638\n",
      "Epoch 252/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7299 - acc: 0.7574\n",
      "Epoch 253/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7241 - acc: 0.7597\n",
      "Epoch 254/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7274 - acc: 0.7585\n",
      "Epoch 255/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7309 - acc: 0.7572\n",
      "Epoch 256/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7220 - acc: 0.7593\n",
      "Epoch 257/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7234 - acc: 0.7596\n",
      "Epoch 258/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7276 - acc: 0.7576\n",
      "Epoch 259/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7323 - acc: 0.7572\n",
      "Epoch 260/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7263 - acc: 0.7585\n",
      "Epoch 261/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7196 - acc: 0.7609\n",
      "Epoch 262/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7292 - acc: 0.7575\n",
      "Epoch 263/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7263 - acc: 0.7601\n",
      "Epoch 264/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7212 - acc: 0.7602\n",
      "Epoch 265/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7145 - acc: 0.7625\n",
      "Epoch 266/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7203 - acc: 0.7600\n",
      "Epoch 267/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7197 - acc: 0.7600\n",
      "Epoch 268/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7272 - acc: 0.7573\n",
      "Epoch 269/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7166 - acc: 0.7623\n",
      "Epoch 270/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7158 - acc: 0.7622\n",
      "Epoch 271/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7188 - acc: 0.7602\n",
      "Epoch 272/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7171 - acc: 0.7639\n",
      "Epoch 273/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7215 - acc: 0.7601\n",
      "Epoch 274/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7254 - acc: 0.7594\n",
      "Epoch 275/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7222 - acc: 0.7609\n",
      "Epoch 276/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7214 - acc: 0.7590\n",
      "Epoch 277/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7130 - acc: 0.7615\n",
      "Epoch 278/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7210 - acc: 0.7607\n",
      "Epoch 279/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7165 - acc: 0.7605\n",
      "Epoch 280/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7099 - acc: 0.7633\n",
      "Epoch 281/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7294 - acc: 0.7594\n",
      "Epoch 282/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7173 - acc: 0.7625\n",
      "Epoch 283/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7203 - acc: 0.7611\n",
      "Epoch 284/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7170 - acc: 0.7625\n",
      "Epoch 285/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7113 - acc: 0.7645\n",
      "Epoch 286/500\n",
      "43954/43954 [==============================] - 3s 70us/step - loss: 0.7152 - acc: 0.7627\n",
      "Epoch 287/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7161 - acc: 0.7629\n",
      "Epoch 288/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7118 - acc: 0.7634\n",
      "Epoch 289/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7158 - acc: 0.7623\n",
      "Epoch 290/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7096 - acc: 0.7625\n",
      "Epoch 291/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7235 - acc: 0.7597\n",
      "Epoch 292/500\n",
      "43954/43954 [==============================] - 3s 70us/step - loss: 0.7114 - acc: 0.7629\n",
      "Epoch 293/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7145 - acc: 0.7630\n",
      "Epoch 294/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7232 - acc: 0.7588\n",
      "Epoch 295/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7124 - acc: 0.7634\n",
      "Epoch 296/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7139 - acc: 0.7638\n",
      "Epoch 297/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7111 - acc: 0.7649\n",
      "Epoch 298/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7093 - acc: 0.7653\n",
      "Epoch 299/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7144 - acc: 0.7613\n",
      "Epoch 300/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7164 - acc: 0.7611\n",
      "Epoch 301/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7150 - acc: 0.7619\n",
      "Epoch 302/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7175 - acc: 0.7621\n",
      "Epoch 303/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7110 - acc: 0.7645\n",
      "Epoch 304/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7129 - acc: 0.7625\n",
      "Epoch 305/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7136 - acc: 0.7621\n",
      "Epoch 306/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7128 - acc: 0.7631\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7166 - acc: 0.7612\n",
      "Epoch 308/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7116 - acc: 0.7631\n",
      "Epoch 309/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7187 - acc: 0.7600\n",
      "Epoch 310/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7100 - acc: 0.7627\n",
      "Epoch 311/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7100 - acc: 0.7655\n",
      "Epoch 312/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7136 - acc: 0.7619\n",
      "Epoch 313/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7115 - acc: 0.7646\n",
      "Epoch 314/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7113 - acc: 0.7638\n",
      "Epoch 315/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7130 - acc: 0.7630\n",
      "Epoch 316/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7042 - acc: 0.7643\n",
      "Epoch 317/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7136 - acc: 0.7626\n",
      "Epoch 318/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7093 - acc: 0.7636\n",
      "Epoch 319/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7090 - acc: 0.7643\n",
      "Epoch 320/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7125 - acc: 0.7626\n",
      "Epoch 321/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7071 - acc: 0.7648\n",
      "Epoch 322/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7070 - acc: 0.7652\n",
      "Epoch 323/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.7086 - acc: 0.7641\n",
      "Epoch 324/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7118 - acc: 0.7629\n",
      "Epoch 325/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7090 - acc: 0.7619\n",
      "Epoch 326/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7079 - acc: 0.7644\n",
      "Epoch 327/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7188 - acc: 0.7593\n",
      "Epoch 328/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7076 - acc: 0.7630\n",
      "Epoch 329/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7093 - acc: 0.7641\n",
      "Epoch 330/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7119 - acc: 0.7633\n",
      "Epoch 331/500\n",
      "43954/43954 [==============================] - 3s 77us/step - loss: 0.7127 - acc: 0.7643\n",
      "Epoch 332/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7107 - acc: 0.7642\n",
      "Epoch 333/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7037 - acc: 0.7677\n",
      "Epoch 334/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7069 - acc: 0.7640\n",
      "Epoch 335/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7056 - acc: 0.7661\n",
      "Epoch 336/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7088 - acc: 0.7635\n",
      "Epoch 337/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7023 - acc: 0.7671\n",
      "Epoch 338/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7078 - acc: 0.7652\n",
      "Epoch 339/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7101 - acc: 0.7640\n",
      "Epoch 340/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7059 - acc: 0.7643\n",
      "Epoch 341/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7103 - acc: 0.7633\n",
      "Epoch 342/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7090 - acc: 0.7658\n",
      "Epoch 343/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7088 - acc: 0.7633\n",
      "Epoch 344/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6985 - acc: 0.7680\n",
      "Epoch 345/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7088 - acc: 0.7637\n",
      "Epoch 346/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7048 - acc: 0.7655\n",
      "Epoch 347/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7055 - acc: 0.7652\n",
      "Epoch 348/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7086 - acc: 0.7656\n",
      "Epoch 349/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7030 - acc: 0.7672\n",
      "Epoch 350/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7040 - acc: 0.7640\n",
      "Epoch 351/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7017 - acc: 0.7680\n",
      "Epoch 352/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7063 - acc: 0.7659\n",
      "Epoch 353/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7048 - acc: 0.7663\n",
      "Epoch 354/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7020 - acc: 0.7668\n",
      "Epoch 355/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7040 - acc: 0.7662\n",
      "Epoch 356/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7031 - acc: 0.7667\n",
      "Epoch 357/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7057 - acc: 0.7661\n",
      "Epoch 358/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7038 - acc: 0.7662\n",
      "Epoch 359/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7067 - acc: 0.7660\n",
      "Epoch 360/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6981 - acc: 0.7674\n",
      "Epoch 361/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7111 - acc: 0.7632\n",
      "Epoch 362/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7073 - acc: 0.7646\n",
      "Epoch 363/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6990 - acc: 0.7663\n",
      "Epoch 364/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6990 - acc: 0.7670\n",
      "Epoch 365/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.7005 - acc: 0.7655\n",
      "Epoch 366/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7029 - acc: 0.7680\n",
      "Epoch 367/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7057 - acc: 0.7652\n",
      "Epoch 368/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7036 - acc: 0.7678\n",
      "Epoch 369/500\n",
      "43954/43954 [==============================] - 4s 83us/step - loss: 0.7017 - acc: 0.7669\n",
      "Epoch 370/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7097 - acc: 0.7641\n",
      "Epoch 371/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 0.7066 - acc: 0.7654\n",
      "Epoch 372/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6938 - acc: 0.7699\n",
      "Epoch 373/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7075 - acc: 0.7665\n",
      "Epoch 374/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7034 - acc: 0.7675\n",
      "Epoch 375/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6909 - acc: 0.7710\n",
      "Epoch 376/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6961 - acc: 0.7671\n",
      "Epoch 377/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7068 - acc: 0.7664\n",
      "Epoch 378/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7069 - acc: 0.7659\n",
      "Epoch 379/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6937 - acc: 0.7690\n",
      "Epoch 380/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7020 - acc: 0.7663\n",
      "Epoch 381/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6946 - acc: 0.7696\n",
      "Epoch 382/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7018 - acc: 0.7671\n",
      "Epoch 383/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.6950 - acc: 0.7693\n",
      "Epoch 384/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6967 - acc: 0.7687\n",
      "Epoch 385/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6995 - acc: 0.7689\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7011 - acc: 0.7674\n",
      "Epoch 387/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7085 - acc: 0.7667\n",
      "Epoch 388/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7019 - acc: 0.7648\n",
      "Epoch 389/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6932 - acc: 0.7691\n",
      "Epoch 390/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.7011 - acc: 0.7676\n",
      "Epoch 391/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6981 - acc: 0.7685\n",
      "Epoch 392/500\n",
      "43954/43954 [==============================] - 4s 80us/step - loss: 0.6984 - acc: 0.7685\n",
      "Epoch 393/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.6946 - acc: 0.7695\n",
      "Epoch 394/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6998 - acc: 0.7679\n",
      "Epoch 395/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7004 - acc: 0.7673\n",
      "Epoch 396/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6995 - acc: 0.7698\n",
      "Epoch 397/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6999 - acc: 0.7669\n",
      "Epoch 398/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7027 - acc: 0.7683\n",
      "Epoch 399/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7025 - acc: 0.7671\n",
      "Epoch 400/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6942 - acc: 0.7687\n",
      "Epoch 401/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6968 - acc: 0.7693\n",
      "Epoch 402/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6925 - acc: 0.7679\n",
      "Epoch 403/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6955 - acc: 0.7698\n",
      "Epoch 404/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6960 - acc: 0.7695\n",
      "Epoch 405/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6964 - acc: 0.7686\n",
      "Epoch 406/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 0.6982 - acc: 0.7681\n",
      "Epoch 407/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6980 - acc: 0.7680\n",
      "Epoch 408/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6959 - acc: 0.7680\n",
      "Epoch 409/500\n",
      "43954/43954 [==============================] - 3s 77us/step - loss: 0.7018 - acc: 0.7663\n",
      "Epoch 410/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6976 - acc: 0.7691\n",
      "Epoch 411/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.6980 - acc: 0.7692\n",
      "Epoch 412/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6959 - acc: 0.7658\n",
      "Epoch 413/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6930 - acc: 0.7687\n",
      "Epoch 414/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6931 - acc: 0.7702\n",
      "Epoch 415/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6915 - acc: 0.7711\n",
      "Epoch 416/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6946 - acc: 0.7676\n",
      "Epoch 417/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7043 - acc: 0.7653\n",
      "Epoch 418/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7014 - acc: 0.7679\n",
      "Epoch 419/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6924 - acc: 0.7682\n",
      "Epoch 420/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.7056 - acc: 0.7648\n",
      "Epoch 421/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6963 - acc: 0.7697\n",
      "Epoch 422/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6959 - acc: 0.7690\n",
      "Epoch 423/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.7032 - acc: 0.7665\n",
      "Epoch 424/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6883 - acc: 0.7720\n",
      "Epoch 425/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6966 - acc: 0.7687\n",
      "Epoch 426/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6961 - acc: 0.7700\n",
      "Epoch 427/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6926 - acc: 0.7688\n",
      "Epoch 428/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6922 - acc: 0.7701\n",
      "Epoch 429/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6942 - acc: 0.7694\n",
      "Epoch 430/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6988 - acc: 0.7668\n",
      "Epoch 431/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6979 - acc: 0.7695\n",
      "Epoch 432/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6930 - acc: 0.7695\n",
      "Epoch 433/500\n",
      "43954/43954 [==============================] - 3s 71us/step - loss: 0.6922 - acc: 0.7698\n",
      "Epoch 434/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6935 - acc: 0.7697\n",
      "Epoch 435/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6947 - acc: 0.7690\n",
      "Epoch 436/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6907 - acc: 0.7701\n",
      "Epoch 437/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6944 - acc: 0.7685\n",
      "Epoch 438/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6931 - acc: 0.7697\n",
      "Epoch 439/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6890 - acc: 0.7705\n",
      "Epoch 440/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6835 - acc: 0.7725\n",
      "Epoch 441/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6912 - acc: 0.7708\n",
      "Epoch 442/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 0.6947 - acc: 0.7691\n",
      "Epoch 443/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6913 - acc: 0.7706\n",
      "Epoch 444/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6887 - acc: 0.7703\n",
      "Epoch 445/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6924 - acc: 0.7715\n",
      "Epoch 446/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6897 - acc: 0.7718\n",
      "Epoch 447/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6763 - acc: 0.7745\n",
      "Epoch 448/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6908 - acc: 0.7696\n",
      "Epoch 449/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6907 - acc: 0.7710\n",
      "Epoch 450/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6950 - acc: 0.7689\n",
      "Epoch 451/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6899 - acc: 0.7705\n",
      "Epoch 452/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6859 - acc: 0.7711\n",
      "Epoch 453/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6830 - acc: 0.7715\n",
      "Epoch 454/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6923 - acc: 0.7719\n",
      "Epoch 455/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6869 - acc: 0.7711\n",
      "Epoch 456/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6882 - acc: 0.7732\n",
      "Epoch 457/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.6870 - acc: 0.7741\n",
      "Epoch 458/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6808 - acc: 0.7722\n",
      "Epoch 459/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6914 - acc: 0.7698\n",
      "Epoch 460/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6899 - acc: 0.7695\n",
      "Epoch 461/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6877 - acc: 0.7713\n",
      "Epoch 462/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6873 - acc: 0.7697\n",
      "Epoch 463/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6939 - acc: 0.7688\n",
      "Epoch 464/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6851 - acc: 0.7718\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6854 - acc: 0.7727\n",
      "Epoch 466/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6870 - acc: 0.7708\n",
      "Epoch 467/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6885 - acc: 0.7707\n",
      "Epoch 468/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6866 - acc: 0.7718\n",
      "Epoch 469/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6983 - acc: 0.7689\n",
      "Epoch 470/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6878 - acc: 0.7712\n",
      "Epoch 471/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6862 - acc: 0.7727\n",
      "Epoch 472/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.6839 - acc: 0.7729\n",
      "Epoch 473/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6838 - acc: 0.7722\n",
      "Epoch 474/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6965 - acc: 0.7691\n",
      "Epoch 475/500\n",
      "43954/43954 [==============================] - 3s 72us/step - loss: 0.6952 - acc: 0.7666\n",
      "Epoch 476/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6964 - acc: 0.7671\n",
      "Epoch 477/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.6870 - acc: 0.7714\n",
      "Epoch 478/500\n",
      "43954/43954 [==============================] - 3s 73us/step - loss: 0.6923 - acc: 0.7696\n",
      "Epoch 479/500\n",
      "43954/43954 [==============================] - 3s 75us/step - loss: 0.6800 - acc: 0.7752\n",
      "Epoch 480/500\n",
      "43954/43954 [==============================] - 4s 84us/step - loss: 0.6862 - acc: 0.7703\n",
      "Epoch 481/500\n",
      "43954/43954 [==============================] - 3s 76us/step - loss: 0.6864 - acc: 0.7697\n",
      "Epoch 482/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6837 - acc: 0.7709\n",
      "Epoch 483/500\n",
      "43954/43954 [==============================] - 3s 74us/step - loss: 0.6862 - acc: 0.7713\n",
      "Epoch 484/500\n",
      "18100/43954 [===========>..................] - ETA: 1s - loss: 0.6759 - acc: 0.7752"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-54a23b524122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmakeModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = makeModel((32,32,3,))\n",
    "model2.summary()\n",
    "hist2 = model2.fit(train_x, to_categorical(train_y,10),batch_size=100,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAALSCAYAAADJDYfxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n26x/Q4MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3dd9a0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learningCurves(hist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model2.predict(test_x)\n",
    "pred = np.argmax(pred,1)\n",
    "pred = pred + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame.from_items([\n",
    "    ('id',list(range(pred.shape[0]))),\n",
    "    ('label', pred)])\n",
    "\n",
    "submission.to_csv('well_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0      9\n",
       "1   1      9\n",
       "2   2      8\n",
       "3   3      1\n",
       "4   4      2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
